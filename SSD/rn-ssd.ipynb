{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "from pycocotools.coco import COCO\n",
    "import cv2\n",
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import torchvision.transforms as transforms\n",
    "from PIL import Image\n",
    "import torchvision.models.detection as models\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "def resize_boxes(boxes, orig_size, target_size):\n",
    "    orig_width, orig_height = orig_size\n",
    "    target_width, target_height = target_size\n",
    "\n",
    "    # Calcular fatores de escala\n",
    "    scale_x = target_width / orig_width\n",
    "    scale_y = target_height / orig_height\n",
    "    #print(boxes)\n",
    "    # Ajustar as caixas\n",
    "    new_boxes = [boxes[0]*scale_x, boxes[1]*scale_y, boxes[2]*scale_x, boxes[3]*scale_y]\n",
    "\n",
    "    return new_boxes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset\n",
    "\n",
    "class COCODataset(Dataset):\n",
    "    def __init__(self, coco_json_path, images_dir, transform=None, resize=None):\n",
    "        self.coco = COCO(coco_json_path)\n",
    "        self.images_dir = images_dir\n",
    "        self.image_ids = self.coco.getImgIds()\n",
    "        self.transform = transform\n",
    "        self.resize = resize\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.image_ids)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        image_id = self.image_ids[idx]\n",
    "        image_data = self.coco.loadImgs(image_id)[0]\n",
    "        image_path = os.path.join(self.images_dir, image_data['file_name'])\n",
    "\n",
    "        # Carregar imagem\n",
    "        image = Image.open(image_path).convert(\"RGB\")\n",
    "        width, height = image.size\n",
    "\n",
    "        # Aplicar transformações\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "\n",
    "        # Obter anotações\n",
    "        ann_ids = self.coco.getAnnIds(imgIds=image_id)\n",
    "        annotations = self.coco.loadAnns(ann_ids)\n",
    "\n",
    "        boxes = []\n",
    "        labels = []\n",
    "        for ann in annotations:\n",
    "            #print(ann['bbox'])\n",
    "            if self.resize is not None:\n",
    "                x, y, w, h = resize_boxes(ann[\"bbox\"], (width, height), self.resize)\n",
    "            else:\n",
    "                x, y, w, h = ann[\"bbox\"]\n",
    "            boxes.append([x, y, x + w, y + h])\n",
    "            labels.append(ann[\"category_id\"])\n",
    "\n",
    "        return image, torch.tensor(boxes), torch.tensor(labels)\n",
    "\n",
    "# Criar dataset\n",
    "# transform = transforms.Compose([\n",
    "#     transforms.Resize((300, 300)),\n",
    "#     transforms.ToTensor(),\n",
    "# ])\n",
    "#dataset = COCODataset(coco_json_path, images_dir, transform=transform, resize=(300, 300))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "from torchvision.models.detection.ssd import ssd300_vgg16\n",
    "from IPython.display import clear_output\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "def treinamento(dataset, num_epochs=150, alias=\"\"):\n",
    "    # Criar modelo SSD com backbone VGG16\n",
    "    model = ssd300_vgg16(pretrained=True).to(device)\n",
    "    model.train()\n",
    "    \n",
    "    # Definir otimizador e loss function\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "    criterion = torch.nn.CrossEntropyLoss()\n",
    "    \n",
    "    out_epochs = []\n",
    "    \n",
    "    # Loop de treinamento\n",
    "\n",
    "    clear_count = 0\n",
    "    clear_rate = 10\n",
    "    #p_images = tqdm(total=len(dataset))\n",
    "    for epoch in tqdm(range(num_epochs), desc=f\"Épocas - {alias}\"):\n",
    "        n = 0\n",
    "        for images, boxes, labels in tqdm(dataset, leave=False, desc=f\"Imagens - {alias}\"):\n",
    "            optimizer.zero_grad()\n",
    "            ann = [{'boxes': boxes.to(device), 'labels':labels.to(device)}]\n",
    "            #annotations = [{k: v.to(device) for k, v in t.items()} for t in annotations]\n",
    "            #print(images.unsqueeze(0).to(device), ann)\n",
    "            #print(images[0], boxes, labels)\n",
    "            # Forward\n",
    "            try:\n",
    "                outputs = model(images.unsqueeze(0).to(device), ann)  # Adiciona batch dimension\n",
    "            except Exception as e:\n",
    "                #print(e)\n",
    "                continue\n",
    "            # Cálculo da loss (simplificada)\n",
    "            # O dicionário de saída contém as perdas\n",
    "            loss = sum(outputs.values())  # Soma todas as perdas para backpropagation\n",
    "            n+=1\n",
    "            #print(n, loss.item())\n",
    "            #clear_count+=1\n",
    "            #if clear_count % clear_rate == 0:\n",
    "            #    clear_output()\n",
    "            #    [print(a) for a in out_epochs]\n",
    "            \n",
    "            # Backpropagation\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            #p_images.update(1)\n",
    "        \n",
    "        #out_epochs.append(f\"Época {epoch+1}/{num_epochs}, Loss: {loss.item()}\")\n",
    "        #print(f\"Época {epoch+1}/{num_epochs}, Loss: {loss.item()}\")\n",
    "        #[print(a) for a in out_epochs]\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "import matplotlib.patches as patches\n",
    "# Carregar imagem\n",
    "#image = cv2.imread('/kaggle/input/celulas/imagens/test/BN117.png')\n",
    "#print(image)\n",
    "#image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "def plot_detections(image, detections, threshold=0.24):\n",
    "    image = torch.mean(image.cpu(), dim=1)\n",
    "    image = image.swapaxes(0,1)\n",
    "    image = image.swapaxes(1,2)\n",
    "    fig, ax = plt.subplots(1, figsize=(10, 6))\n",
    "    ax.imshow(image)\n",
    "    print(detections)\n",
    "    for box, score, label in zip(detections[0][\"boxes\"].to('cpu'), detections[0][\"scores\"].to('cpu'), detections[0][\"labels\"].to('cpu')):\n",
    "        if score > threshold:\n",
    "            x_min, y_min, x_max, y_max = box\n",
    "            colors = {0: 'r', 1: 'g', 2:'b'}\n",
    "            \n",
    "            rect = patches.Rectangle((x_min, y_min), x_max - x_min, y_max - y_min, linewidth=2, edgecolor=colors[label.item()], facecolor='none')\n",
    "            print(box)\n",
    "            print(rect)\n",
    "            print(label)\n",
    "            ax.add_patch(rect)\n",
    "\n",
    "    plt.show()\n",
    "\n",
    "#plot_detections(image_tensor, detections)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.models.detection as models\n",
    "from pycocotools.coco import COCO\n",
    "from pycocotools.cocoeval import COCOeval\n",
    "import os\n",
    "from PIL import Image\n",
    "import json\n",
    "import sys\n",
    "\n",
    "def avaliacao(model_path, images_path, ann_path, transform, alias=\"\"):\n",
    "    # Carregar o modelo SSD treinado\n",
    "    model = models.ssd300_vgg16(pretrained=False)\n",
    "    model.load_state_dict(torch.load(model_path, map_location=\"cpu\"))\n",
    "    model.eval()  # Modo de inferência\n",
    "    \n",
    "    # Carregar a base de teste (COCO JSON)\n",
    "    coco_gt = COCO(ann_path)  # Ground Truth\n",
    "    images_dir = images_path\n",
    "    \n",
    "    \n",
    "    # Lista para armazenar as previsões convertidas para COCO JSON\n",
    "    coco_results = []\n",
    "    \n",
    "    # **4️⃣ Iterar sobre todas as imagens da base de teste**\n",
    "    for img_id in tqdm(coco_gt.getImgIds(), desc=f\"Avaliando - {alias}\"):\n",
    "        img_info = coco_gt.loadImgs(img_id)[0]\n",
    "        img_path = os.path.join(images_dir, img_info[\"file_name\"])\n",
    "    \n",
    "        # Carregar a imagem e aplicar as transformações\n",
    "        image = Image.open(img_path).convert(\"RGB\")\n",
    "        image = transform(image).unsqueeze(0)  # Adicionar batch dimension\n",
    "    \n",
    "        # Fazer a detecção\n",
    "        with torch.no_grad():\n",
    "            outputs = model(image)\n",
    "    \n",
    "        # Extrair caixas, rótulos e scores das previsões\n",
    "        pred_boxes = outputs[0][\"boxes\"].tolist()\n",
    "        pred_scores = outputs[0][\"scores\"].tolist()\n",
    "        pred_labels = outputs[0][\"labels\"].tolist()\n",
    "    \n",
    "        # **5️⃣ Converter as previsões para o formato COCO**\n",
    "        for box, score, label in zip(pred_boxes, pred_scores, pred_labels):\n",
    "            x_min, y_min, x_max, y_max = box\n",
    "            coco_results.append({\n",
    "                \"image_id\": img_id,\n",
    "                \"category_id\": label,  # ID da classe\n",
    "                \"bbox\": [x_min, y_min, x_max - x_min, y_max - y_min],  # Convertendo para formato COCO (x, y, largura, altura)\n",
    "                \"score\": score\n",
    "            })\n",
    "    \n",
    "    # **6️⃣ Salvar as previsões no formato COCO JSON**\n",
    "    with open(f\"predictions_{alias}.json\", \"w\") as f:\n",
    "        json.dump(coco_results, f, indent=4)\n",
    "\n",
    "    coco_dt = coco_gt.loadRes(f\"predictions_{alias}.json\")\n",
    "    metrics = evaluate_detections(ann_path, f\"predictions_{alias}.json\")\n",
    "\n",
    "    with open(f\"metrics_{alias}.json\", \"w\") as f:\n",
    "        f.write(str(metrics))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import numpy as np\n",
    "from collections import defaultdict\n",
    "\n",
    "def load_coco_labels(json_path, tam):\n",
    "    \"\"\"Carrega as anotações COCO de um arquivo JSON.\"\"\"\n",
    "    with open(json_path, 'r') as f:\n",
    "        data = json.load(f)\n",
    "    for a in range(len(data['annotations'])):\n",
    "        data['annotations'][a]['bbox'] = resize_boxes(data['annotations'][a]['bbox'], (2048, 1536), tam)\n",
    "    \n",
    "    annotations = defaultdict(list)\n",
    "    for ann in data['annotations']:\n",
    "        image_id = ann['image_id']\n",
    "        x_min, y_min, width, height = ann['bbox']\n",
    "        x_max, y_max = x_min + width, y_min + height\n",
    "        class_id = ann['category_id']\n",
    "        annotations[image_id].append([class_id, x_min, y_min, x_max, y_max])\n",
    "    \n",
    "    return annotations\n",
    "\n",
    "def load_coco_predictions(json_path, score_threshold=0.0):\n",
    "    \"\"\"Carrega predições COCO a partir de um arquivo JSON, filtrando por score.\"\"\"\n",
    "    with open(json_path, 'r') as f:\n",
    "        data = json.load(f)\n",
    "    \n",
    "    predictions = defaultdict(list)\n",
    "    for pred in data:\n",
    "        if pred['score'] >= score_threshold:\n",
    "            image_id = pred['image_id']\n",
    "            category_id = pred['category_id']\n",
    "            bbox = pred['bbox']\n",
    "            x_min, y_min, width, height = bbox\n",
    "            x_max = x_min + width\n",
    "            y_max = y_min + height\n",
    "            predictions[image_id].append([category_id, x_min, y_min, x_max, y_max])\n",
    "    \n",
    "    return predictions\n",
    "\n",
    "def calculate_iou(box1, box2):\n",
    "    \"\"\"Calcula o IoU entre duas bounding boxes.\"\"\"\n",
    "    x1_min, y1_min, x1_max, y1_max = box1[1:]\n",
    "    x2_min, y2_min, x2_max, y2_max = box2[1:]\n",
    "    \n",
    "    xi1, yi1 = max(x1_min, x2_min), max(y1_min, y2_min)\n",
    "    xi2, yi2 = min(x1_max, x2_max), min(y1_max, y2_max)\n",
    "    inter_area = max(0, xi2 - xi1) * max(0, yi2 - yi1)\n",
    "    \n",
    "    box1_area = (x1_max - x1_min) * (y1_max - y1_min)\n",
    "    box2_area = (x2_max - x2_min) * (y2_max - y2_min)\n",
    "    union_area = box1_area + box2_area - inter_area\n",
    "    \n",
    "    return inter_area / union_area if union_area > 0 else 0\n",
    "\n",
    "def compute_ap(recalls, precisions):\n",
    "    \"\"\"Calcula o AP (Average Precision) por interpolação da curva precisão-recall.\"\"\"\n",
    "    recalls = np.concatenate(([0.0], np.array(recalls), [1.0]))\n",
    "    precisions = np.concatenate(([0.0], np.array(precisions), [0.0]))\n",
    "    \n",
    "    for i in range(len(precisions) - 1, 0, -1):\n",
    "        precisions[i - 1] = max(precisions[i - 1], precisions[i])\n",
    "    \n",
    "    indices = np.where(np.diff(recalls) > 0)[0]\n",
    "    ap = np.sum((recalls[indices + 1] - recalls[indices]) * precisions[indices + 1])\n",
    "    return ap\n",
    "\n",
    "def evaluate_detections(gt_json, pred_json, iou_thresholds=[0.2, 0.5, 0.55, 0.60, 0.65, 0.70, 0.75, 0.80, 0.85, 0.90, 0.95], tam=(300, 300)):\n",
    "    \"\"\"Avalia as predições COCO em relação ao ground truth.\"\"\"\n",
    "    gt_labels = load_coco_labels(gt_json, tam)\n",
    "    pred_labels = load_coco_predictions(pred_json)\n",
    "\n",
    "    \n",
    "    TP, FP, FN = defaultdict(lambda: defaultdict(int)), defaultdict(lambda: defaultdict(int)), defaultdict(lambda: defaultdict(int))\n",
    "    \n",
    "    for img_id in gt_labels.keys():\n",
    "        gt_bboxes = gt_labels[img_id]\n",
    "        pred_bboxes = pred_labels.get(img_id, [])\n",
    "        \n",
    "        for iou_threshold in iou_thresholds:\n",
    "            matched = set()\n",
    "            \n",
    "            for pred in pred_bboxes:\n",
    "                best_iou, best_match = 0, None\n",
    "                for idx, gt in enumerate(gt_bboxes):\n",
    "                    if gt[0] == pred[0]:\n",
    "                        iou = calculate_iou(pred, gt)\n",
    "                        if iou > best_iou:\n",
    "                            best_iou = iou\n",
    "                            best_match = idx\n",
    "                \n",
    "                if best_iou >= iou_threshold and best_match is not None and best_match not in matched:\n",
    "                    TP[iou_threshold][pred[0]] += 1\n",
    "                    matched.add(best_match)\n",
    "                else:\n",
    "                    FP[iou_threshold][pred[0]] += 1\n",
    "            \n",
    "            for idx, gt in enumerate(gt_bboxes):\n",
    "                if idx not in matched:\n",
    "                    FN[iou_threshold][gt[0]] += 1\n",
    "    \n",
    "    metrics = {}\n",
    "    for iou_threshold in iou_thresholds:\n",
    "        precisions, recalls, aps = {}, {}, {}\n",
    "        classes = set(TP[iou_threshold].keys()) | set(FN[iou_threshold].keys())\n",
    "        for cls in classes:\n",
    "            precisions[cls] = TP[iou_threshold][cls] / (TP[iou_threshold][cls] + FP[iou_threshold][cls]) if (TP[iou_threshold][cls] + FP[iou_threshold][cls]) > 0 else 0\n",
    "            recalls[cls] = TP[iou_threshold][cls] / (TP[iou_threshold][cls] + FN[iou_threshold][cls]) if (TP[iou_threshold][cls] + FN[iou_threshold][cls]) > 0 else 0\n",
    "        metrics[iou_threshold] = {\"precisions\": precisions, \"recalls\": recalls}\n",
    "    \n",
    "    for cls in classes:\n",
    "        aps[cls] = compute_ap([metrics[iou]['recalls'][cls] for iou in iou_thresholds],\n",
    "                              [metrics[iou]['precisions'][cls] for iou in iou_thresholds])\n",
    "    \n",
    "    for iou_threshold in iou_thresholds:\n",
    "        metrics[iou_threshold][\"aps\"] = aps\n",
    "    \n",
    "    return metrics\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "tamanhos = [(300, 300),\n",
    "            (640, 640), (720, 720), (1080, 1080)]\n",
    "num_classes = [\n",
    "    (1,\n",
    "    \"/kaggle/input/celulas/annotations_vc/annotation_1classe_treino.json\",\n",
    "    \"/kaggle/input/celulas/annotations_vc/annotation_1classe_teste.json\"),\n",
    "    (\n",
    "       2,\n",
    "       \"/kaggle/input/celulas/annotations_vc/annotation_2classe_treino.json\",\n",
    "       \"/kaggle/input/celulas/annotations_vc/annotation_2classe_test.json\"\n",
    "    ),\n",
    "    (3, \n",
    "     \"/kaggle/input/celulas/annotation/annotation.json\", \n",
    "     \"/kaggle/input/celulas/annotation_test.json\"),\n",
    "\n",
    "    ] # (numero de classes, arquivo de anotacoes de treino, arquivo de anotacoes de teste)\n",
    "\n",
    "images_train = \"/kaggle/input/celulas/annotation/imagens/train\"\n",
    "images_test = \"/kaggle/input/celulas/annotation/imagens/test\"\n",
    "\n",
    "for classes, ann_train, ann_test in num_classes:\n",
    "    for tamanho in tamanhos:\n",
    "        # if classes == 3 and tamanho in [(300, 300), (640, 640)]:\n",
    "        #     print(\"passando\", classes, tamanho)\n",
    "        #     continue\n",
    "        alias = f\"{'_'.join(map(str, tamanho))}_{classes}_classes\"\n",
    "        print(alias)\n",
    "        # Criar dataset\n",
    "        transform = transforms.Compose([\n",
    "            transforms.Resize(tamanho),\n",
    "            transforms.ToTensor(),\n",
    "        ])\n",
    "        dataset = COCODataset(ann_train, images_train, transform=transform, resize=tamanho)\n",
    "        \n",
    "        # # treinamento\n",
    "        model = treinamento(dataset, num_epochs=150, alias=alias)\n",
    "        # /kaggle/input/modelos-treinados\n",
    "        PATH = f'/kaggle/input/celulas/ssdresultados/resultados treinamento/{classes}/{tamanho[0]}/modelo_{\"_\".join(map(str, tamanho))}_{classes}_classes.pth'\n",
    "        torch.save(model.state_dict(), PATH)\n",
    "        \n",
    "        # avaliacao\n",
    "        \n",
    "        print(\"avaliando modelo -\", alias)\n",
    "        avaliacao(PATH, images_test, ann_test, transform, alias=alias)\n",
    "        metrics = evaluate_detections(ann_test, f\"/kaggle/working/predictions_{alias}.json\", tam=tamanho)\n",
    "        # Exibe as métricas\n",
    "        print(\"Classe | Precisão | Recall | AP50 | AP75\")\n",
    "        print(\"--------------------------------------------------\")\n",
    "        t = 0.5\n",
    "        for cls in metrics[t]['precisions'].keys():\n",
    "            prec50 = metrics[t]['precisions'][cls]\n",
    "            rec50 = metrics[t]['recalls'][cls]\n",
    "            ap50 = metrics[t]['aps'][cls]\n",
    "            ap5095 = (metrics[t]['aps'][cls] + metrics[0.55]['aps'][cls] + metrics[0.60]['aps'][cls] + metrics[0.65]['aps'][cls] + metrics[0.70]['aps'][cls] + metrics[0.75]['aps'][cls] + metrics[0.80]['aps'][cls] + metrics[0.85]['aps'][cls] + metrics[0.90]['aps'][cls] + metrics[0.95]['aps'][cls]) / 10\n",
    "            print(f\"{cls:^6} | {prec50:.4f} | {rec50:.4f} | {ap50:.4f} | {ap5095:.4f}\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
