{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "!pip install ultralytics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "!pip install opencv-python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import cv2\n",
    "from ultralytics import YOLO\n",
    "from collections import defaultdict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "model_BN_path = \"/kaggle/input/models/yolo11l_3classes1080.pt\"\n",
    "model_MN_path = \"/kaggle/input/models/yolo11s_1classe1080.pt\"\n",
    "\n",
    "model_BN = YOLO(model_BN_path)\n",
    "model_MN = YOLO(model_MN_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "model_BN.predict(source=\"/kaggle/input/detectionbnmn-3classes/images/test\", save=False, show_conf=False, show_labels=False, save_txt=True)\n",
    "model_MN.predict(source=\"/kaggle/input/detectionbnmn-3classes/images/test\", save=False, show_conf=False, show_labels=False, save_txt=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Remoção da classe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "input_dir = '/kaggle/input/predicts-ensemble/predictBN11l/kaggle/working/runs/detect/predict/labels'\n",
    "output_dir = '/kaggle/working/rmv_predict_11l'\n",
    "\n",
    "class_id_to_remove = '2'\n",
    "\n",
    "# Cria o diretório de saída, caso ele não exista\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "# Loop pelos arquivos de anotação no diretório de entrada\n",
    "for filename in os.listdir(input_dir):\n",
    "    if filename.endswith('.txt'):\n",
    "        input_path = os.path.join(input_dir, filename)\n",
    "        output_path = os.path.join(output_dir, filename)\n",
    "\n",
    "        # Ler o arquivo e filtrar as linhas\n",
    "        with open(input_path, 'r') as file:\n",
    "            lines = file.readlines()\n",
    "\n",
    "        # Manter apenas as linhas que não têm o class_id que queremos remover\n",
    "        new_lines = [line for line in lines if not line.startswith(class_id_to_remove)]\n",
    "\n",
    "        # Escrever o novo arquivo no diretório de saída\n",
    "        with open(output_path, 'w') as file:\n",
    "            file.writelines(new_lines)\n",
    "\n",
    "print(\"Anotações da classe MN removidas e salvas no novo diretório com sucesso.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Junção das classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "input_dir1 = '/kaggle/working/rmv_predict_11l'\n",
    "input_dir2 = '/kaggle/input/predicts-ensemble/predictMN11s/kaggle/working/runs/detect/predict2/labels'\n",
    "\n",
    "output_dir = '/kaggle/working/final_predict_ensemble'\n",
    "\n",
    "# Cria o diretório de saída, caso ele não exista\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "for filename in os.listdir(input_dir1):\n",
    "    if filename.endswith('.txt'):\n",
    "        input_path1 = os.path.join(input_dir1, filename)\n",
    "        input_path2 = os.path.join(input_dir2, filename)\n",
    "        output_path = os.path.join(output_dir, filename)\n",
    "\n",
    "        with open(input_path1, 'r') as file1:\n",
    "            dir1 = file1.readlines()\n",
    "\n",
    "        if os.path.exists(input_path2):\n",
    "            with open(input_path2, 'r') as file2:\n",
    "                dir2 = file2.readlines()\n",
    "        else: \n",
    "            dir2 = []\n",
    "\n",
    "        final_dir = dir1 + dir2\n",
    "\n",
    "        with open(output_path, 'w') as f_out:\n",
    "            f_out.writelines(final_dir)\n",
    "\n",
    "print(\"Processo concluído\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cálculo das métricas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "from collections import defaultdict\n",
    "\n",
    "def load_yolo_labels(txt_path):\n",
    "    \"\"\"Carrega as anotações YOLO de um arquivo TXT.\"\"\"\n",
    "    labels = []\n",
    "    with open(txt_path, 'r') as f:\n",
    "        for line in f.readlines():\n",
    "            values = list(map(float, line.strip().split()))\n",
    "            labels.append(values)  # Formato: [classe, x_c, y_c, w, h]\n",
    "    return labels\n",
    "\n",
    "def yolo_to_bbox(label, img_width=1, img_height=1):\n",
    "    \"\"\"Converte as coordenadas YOLO para coordenadas absolutas.\"\"\"\n",
    "    classe, x_c, y_c, w, h = label[:5]\n",
    "    x_min = (x_c - w / 2) * img_width\n",
    "    y_min = (y_c - h / 2) * img_height\n",
    "    x_max = (x_c + w / 2) * img_width\n",
    "    y_max = (y_c + h / 2) * img_height\n",
    "    return [int(classe), x_min, y_min, x_max, y_max]\n",
    "\n",
    "def calculate_iou(box1, box2):\n",
    "    \"\"\"Calcula o IoU entre duas bounding boxes.\"\"\"\n",
    "    x1_min, y1_min, x1_max, y1_max = box1[1:]\n",
    "    x2_min, y2_min, x2_max, y2_max = box2[1:]\n",
    "    \n",
    "    xi1 = max(x1_min, x2_min)\n",
    "    yi1 = max(y1_min, y2_min)\n",
    "    xi2 = min(x1_max, x2_max)\n",
    "    yi2 = min(y1_max, y2_max)\n",
    "    inter_area = max(0, xi2 - xi1) * max(0, yi2 - yi1)\n",
    "    \n",
    "    box1_area = (x1_max - x1_min) * (y1_max - y1_min)\n",
    "    box2_area = (x2_max - x2_min) * (y2_max - y2_min)\n",
    "    union_area = box1_area + box2_area - inter_area\n",
    "    \n",
    "    return inter_area / union_area if union_area > 0 else 0\n",
    "\n",
    "def compute_ap(recalls, precisions):\n",
    "    \"\"\"\n",
    "    Calcula o AP (Average Precision) usando interpolação da curva de precisão-recall.\n",
    "    \"\"\"\n",
    "    recalls = np.array(recalls)\n",
    "    precisions = np.array(precisions)\n",
    "\n",
    "    # Adiciona (0,1) e (1,0) para garantir a interpolação correta\n",
    "    recalls = np.concatenate(([0.0], recalls, [1.0]))\n",
    "    precisions = np.concatenate(([0.0], precisions, [0.0]))\n",
    "\n",
    "    # Garante que a precisão seja monótona não crescente\n",
    "    for i in range(len(precisions) - 1, 0, -1):\n",
    "        precisions[i - 1] = max(precisions[i - 1], precisions[i])\n",
    "\n",
    "    # Encontra os pontos onde o recall muda\n",
    "    indices = np.where(np.diff(recalls) > 0)[0]\n",
    "\n",
    "    # Calcula a área sob a curva de precisão-recall (AP)\n",
    "    ap = np.sum((recalls[indices + 1] - recalls[indices]) * precisions[indices + 1])\n",
    "\n",
    "    return ap\n",
    "\n",
    "def evaluate_detections(gt_dir, pred_dir, iou_thresholds=[0.5, 0.55, 0.60, 0.65, 0.70, 0.75, 0.80, 0.85, 0.90, 0.95]):\n",
    "    \"\"\"Avalia as predições YOLO em relação ao ground truth.\"\"\"\n",
    "    gt_files = {f[:-4]: os.path.join(gt_dir, f) for f in os.listdir(gt_dir) if f.endswith('.txt')}\n",
    "    pred_files = {f[:-4]: os.path.join(pred_dir, f) for f in os.listdir(pred_dir) if f.endswith('.txt')}\n",
    "    \n",
    "    TP, FP, FN = defaultdict(lambda: defaultdict(int)), defaultdict(lambda: defaultdict(int)), defaultdict(lambda: defaultdict(int))\n",
    "    \n",
    "    for file_id in gt_files.keys():\n",
    "        gt_labels = [yolo_to_bbox(lbl) for lbl in load_yolo_labels(gt_files[file_id])]\n",
    "\n",
    "        if file_id in pred_files:\n",
    "            pred_labels = [yolo_to_bbox(lbl) for lbl in load_yolo_labels(pred_files[file_id])]\n",
    "\n",
    "        else: \n",
    "            pred_labels = []\n",
    "        \n",
    "        for iou_threshold in iou_thresholds:\n",
    "            matched = set()\n",
    "            \n",
    "            for pred in pred_labels:\n",
    "                best_iou = 0\n",
    "                best_match = None\n",
    "                for idx, gt in enumerate(gt_labels):\n",
    "                    if gt[0] == pred[0]:  # Mesma classe\n",
    "                        iou = calculate_iou(pred, gt)\n",
    "                        # iou = get_iou(gt, pred)\n",
    "                        if iou > best_iou:\n",
    "                            best_iou = iou\n",
    "                            best_match = idx\n",
    "                \n",
    "                if best_iou >= iou_threshold and best_match is not None and best_match not in matched:\n",
    "                    TP[iou_threshold][pred[0]] += 1\n",
    "                    matched.add(best_match)\n",
    "                else:\n",
    "                    FP[iou_threshold][pred[0]] += 1\n",
    "            \n",
    "            for idx, gt in enumerate(gt_labels):\n",
    "                if idx not in matched:\n",
    "                    FN[iou_threshold][gt[0]] += 1\n",
    "    \n",
    "    metrics = {}\n",
    "    for iou_threshold in iou_thresholds:\n",
    "        precisions, recalls, aps = {}, {}, {}\n",
    "        for cls in [0, 1, 2]:\n",
    "            precisions[cls] = TP[iou_threshold][cls] / (TP[iou_threshold][cls] + FP[iou_threshold][cls]) if (TP[iou_threshold][cls] + FP[iou_threshold][cls]) > 0 else 0\n",
    "            recalls[cls] = TP[iou_threshold][cls] / (TP[iou_threshold][cls] + FN[iou_threshold][cls]) if (TP[iou_threshold][cls] + FN[iou_threshold][cls]) > 0 else 0\n",
    "            # aps[cls] = precisions[cls] * recalls[cls]  # Aproximação do AP\n",
    "        metrics[iou_threshold] = {\"precisions\": precisions, \"recalls\": recalls, \"aps\": aps}\n",
    "\n",
    "    aps = {cls: compute_ap(\n",
    "        [metrics[iou]['recalls'][cls] for iou in iou_thresholds], \n",
    "        [metrics[iou]['precisions'][cls] for iou in iou_thresholds])\n",
    "        for cls in [0, 1, 2]}  # Alterar para `set(TP[iou_threshold].keys())` se quiser todas as classes dinâmicas\n",
    "    \n",
    "    # Adiciona os APs ao dicionário de métricas\n",
    "    for iou_threshold in iou_thresholds:\n",
    "        metrics[iou_threshold][\"aps\"] = aps\n",
    "    \n",
    "    return metrics\n",
    "\n",
    "gt_dir = '/kaggle/input/detectionbnmn-3classes/labels/test'\n",
    "pred_dir = '/kaggle/input/predicts-ensemble/predict_ensemble/kaggle/working/final_predict_ensemble'\n",
    "metrics = evaluate_detections(gt_dir, pred_dir, iou_thresholds=[0.5, 0.55, 0.60, 0.65, 0.70, 0.75, 0.80, 0.85, 0.90, 0.95])\n",
    "\n",
    "print(\"Classe | Precisão | Recall | mAP50 | mAP50-95\")\n",
    "print(\"--------------------------------------------------\")\n",
    "for cls in [0, 1, 2]:\n",
    "    prec50 = metrics[0.5]['precisions'][cls]\n",
    "    rec50 = metrics[0.5]['recalls'][cls]\n",
    "    ap50 = metrics[0.5]['aps'][cls]\n",
    "    ap5095 = (metrics[0.5]['aps'][cls] + metrics[0.55]['aps'][cls] + metrics[0.60]['aps'][cls] + metrics[0.65]['aps'][cls] + metrics[0.70]['aps'][cls] + metrics[0.75]['aps'][cls] + metrics[0.80]['aps'][cls] + metrics[0.85]['aps'][cls] + metrics[0.90]['aps'][cls] + metrics[0.95]['aps'][cls]) / 10  # Aproximação para mAP50-95\n",
    "    print(f\"{cls:^6} | {prec50:.4f} | {rec50:.4f} | {ap50:.4f} | {ap5095:.4f}\")\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
